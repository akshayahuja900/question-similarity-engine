{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Similarity Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load required packages, functions and pickle objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_10594567781208686036() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_10594567781208686036()\">Toggle show/hide</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "\n",
    "# Start with loading all necessary libraries\n",
    "#Importing general purpose python libraries below\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime\n",
    "#tqdm is great for measure progress on long-running tasks\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import pickle\n",
    "\n",
    "#For charts and visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#For Wordclouds\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "#For NLP & Feature Extraction\n",
    "from textatistic import Textatistic\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
    "\n",
    "#For modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Import the classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "#Read dataset\n",
    "df = pd.read_csv('final/df_final_20210405.csv')\n",
    "\n",
    "#Initialize Functions\n",
    "def normalized_word_share(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].replace('?','').split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].replace('?','').split(\" \")))    \n",
    "    return 2.0 * len(w1 & w2)/(len(w1) + len(w2))\n",
    "def preprocess_entities(text):\n",
    "    doc = nlp(text, disable = ['parser'])\n",
    "    return [X.text for X in doc.ents], [X.label_ for X in doc.ents]\n",
    "#Tokenization and Lemmatization\n",
    "def preprocess(text):\n",
    "    # Create Doc object\n",
    "    doc = nlp(text.lower(), disable=['ner', 'parser'])\n",
    "    # Generate lemmas\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    # Remove stopwords and non-alphabetic characters\n",
    "    a_lemmas = [lemma for lemma in lemmas \n",
    "            if lemma.isalpha() and lemma not in STOP_WORDS]\n",
    "    return ' '.join(a_lemmas)\n",
    "\n",
    "#Load Pickle Objects\n",
    "tfid_vectorizer = pickle.load(open(\"final/tfid_vectorizer.p\",\"rb\"))\n",
    "q1weights = pickle.load(open(\"final/q1weights.p\",\"rb\"))\n",
    "scaler = pickle.load(open(\"final/scaler.p\",\"rb\"))\n",
    "model = pickle.load(open(\"final/model.p\",\"rb\"))\n",
    "clf = pickle.load(open(\"final/clf.p\",\"rb\"))\n",
    "nlp = pickle.load(open(\"final/nlp.p\",\"rb\"))\n",
    "doc_embeddings1 = pickle.load(open(\"final/doc_embeddings1.p\",\"rb\"))\n",
    "sbert_model = pickle.load(open(\"final/sbert_model.p\",\"rb\"))\n",
    "features = pickle.load(open(\"final/features.p\",\"rb\"))\n",
    "\n",
    "#load nlp spacy lg model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def run_demo():\n",
    "    user_input_question = input()\n",
    "\n",
    "    # initial set of features\n",
    "    demo_df=df[['qid1','question1','q1_cleaned','entities1','entity_types1','q1len','q1_n_words']]\n",
    "    demo_df['question2']=user_input_question\n",
    "    demo_df['q2len'] = demo_df['question2'].str.len()\n",
    "    demo_df['qlen_diff']= abs(demo_df['q1len'] - demo_df['q2len'])\n",
    "    demo_df['q2_n_words'] = demo_df['question2'].apply(lambda row: len(row.split(\" \")))\n",
    "    demo_df['q_n_words_diff'] = abs(demo_df['q1_n_words'] - demo_df['q2_n_words'])\n",
    "    demo_df['word_share'] = demo_df.apply(normalized_word_share, axis=1)\n",
    "\n",
    "    # preprocess user input\n",
    "    demo_df['q2_cleaned'] = preprocess(user_input_question)\n",
    "\n",
    "    # create feature tfidf_word_match\n",
    "    demo_tfidf_wm = tfid_vectorizer.transform([user_input_question])\n",
    "    demo_b1 = np.array(demo_tfidf_wm.todense()[0])\n",
    "    demo_q2weights={}\n",
    "    for ix,i in enumerate(demo_b1[0]):\n",
    "        if i>0:\n",
    "            demo_q2weights[tfidf_tokens[ix]] = i\n",
    "    demo_tfidf_word_match=[]\n",
    "    for ix in range(df.shape[0]):\n",
    "        q1words = {}\n",
    "        q2words = {}\n",
    "        for word in str(demo_df.iloc[ix]['q1_cleaned']).lower().split():\n",
    "            if word not in STOP_WORDS:\n",
    "                q1words[word] = 1\n",
    "        for word in str(demo_df.iloc[ix]['q2_cleaned']).lower().split():\n",
    "            if word not in STOP_WORDS:\n",
    "                q2words[word] = 1\n",
    "        if len(q1words) == 0 or len(q2words) == 0:\n",
    "            # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "            demo_tfidf_word_match.append(0)\n",
    "        else:\n",
    "            shared_weights = [q1weights[ix][w] for w in q1words.keys() if w in q1weights[ix].keys() if w in q2words] + [demo_q2weights[w] for w in q2words.keys() if w in demo_q2weights.keys() if w in q1words]\n",
    "            total_weights = [q1weights[ix][w] for w in q1words if w in q1weights[ix].keys()] + [demo_q2weights[w] for w in q2words if w in demo_q2weights.keys()]\n",
    "            R = np.sum(shared_weights) / np.sum(total_weights)\n",
    "            demo_tfidf_word_match.append(R)\n",
    "    #     if ix%50000==0:\n",
    "    #         print('almost there')\n",
    "    demo_df['tfidf_word_match']=demo_tfidf_word_match\n",
    "\n",
    "    #bert cosine similarity scores\n",
    "    input_embedding = sbert_model.encode(user_input_question)\n",
    "\n",
    "    bert_cosine_sim = []\n",
    "    for i in range(len(doc_embeddings1)):\n",
    "        bert_cosine_sim.append(float(np.dot(doc_embeddings1[i],input_embedding.T)/\n",
    "                                     (np.linalg.norm(doc_embeddings1[i], ord=2)*\n",
    "                                      np.linalg.norm(input_embedding, ord=2))))\n",
    "    demo_df['bert_cosine_sim_'] = bert_cosine_sim\n",
    "\n",
    "    # Named Entity Recognition Features\n",
    "    q2_ents=0\n",
    "    if preprocess_entities(user_input_question)[0] == []:\n",
    "        q2_ents=0\n",
    "    else:\n",
    "        q2_ents = len(preprocess_entities(user_input_question)[0])\n",
    "    #Compare entities between questions\n",
    "    demo_df['diff_num_entities'] = demo_df.apply(lambda x: abs(len(x['entities1']) - q2_ents), axis = 1)\n",
    "\n",
    "    X = scaler.transform(demo_df[features])\n",
    "    X=np.nan_to_num(X)\n",
    "    print('Model Ready!')\n",
    "    yproba = model.predict_proba(X)[::,1]\n",
    "    \n",
    "    y_pred=clf.predict(X)\n",
    "\n",
    "    demo_df['model_score']=yproba\n",
    "    demo_df['model_pred']=y_pred\n",
    "\n",
    "    # print(user_input_question)\n",
    "    #print('Here are some previously answered questions:')\n",
    "    return demo_df\n",
    "    #return demo_df[['question1','bert_cosine_sim_','model_score']].nlargest(5,'model_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enter Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I combat climate change?\n",
      "Model Ready!\n"
     ]
    }
   ],
   "source": [
    "df1=run_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. View Similar Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>model_score</th>\n",
       "      <th>model_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40083</th>\n",
       "      <td>What important steps can we take as individuals to combat climate change?</td>\n",
       "      <td>0.631991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20290</th>\n",
       "      <td>Can climate change be reversed?</td>\n",
       "      <td>0.622994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35692</th>\n",
       "      <td>Is Climate change real?</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64612</th>\n",
       "      <td>Will technology ever allow us to alter the climate?</td>\n",
       "      <td>0.545552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41759</th>\n",
       "      <td>What's the difference between climate change and global warming?</td>\n",
       "      <td>0.520883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       question1  \\\n",
       "40083  What important steps can we take as individuals to combat climate change?   \n",
       "20290  Can climate change be reversed?                                             \n",
       "35692  Is Climate change real?                                                     \n",
       "64612  Will technology ever allow us to alter the climate?                         \n",
       "41759  What's the difference between climate change and global warming?            \n",
       "\n",
       "       model_score  model_pred  \n",
       "40083  0.631991     1           \n",
       "20290  0.622994     1           \n",
       "35692  0.599000     1           \n",
       "64612  0.545552     1           \n",
       "41759  0.520883     1           "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['question1','model_score','model_pred']].nlargest(5,'model_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "  \n",
    "   \n",
    "    \n",
    "      \n",
    "       \n",
    "        \n",
    "         \n",
    "          \n",
    "           \n",
    "            \n",
    "             \n",
    "              \n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
